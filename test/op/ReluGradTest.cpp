//
//  ReluGradTest.cpp
//  MNNTests
//
//  Created by MNN on 2019/10/16.
//  Copyright Â© 2018, Alibaba Group Holding Limited
//

#include <MNN/MNNForwardType.h>
#include <MNN/expr/Expr.hpp>
#include <MNN/expr/ExprCreator.hpp>
#include <MNN/expr/Optimizer.hpp>
#include <string>
#include <vector>
#include "MNNTestSuite.h"
#include "MNN_generated.h"
#include "TestUtils.h"

using namespace MNN::Express;

static VARP _ReluGrad(VARP originInput, VARP inputGrad) {
    using namespace MNN;
    std::unique_ptr<OpT> relu(new OpT);
    relu->type                 = OpType_ReluGrad;
    relu->main.type            = OpParameter_Relu;
    relu->main.value           = new ReluT;
    relu->main.AsRelu()->slope = 0.0f;
    return Variable::create(Expr::create(std::move(relu), {originInput, inputGrad}));
}

static VARP _Relu6Grad(VARP originInput, VARP inputGrad) {
    using namespace MNN;
    std::unique_ptr<OpT> relu6(new OpT);
    relu6->type       = OpType_Relu6Grad;
    relu6->main.type  = OpParameter_Relu6;
    relu6->main.value = new Relu6T;
    return Variable::create(Expr::create(std::move(relu6), {originInput, inputGrad}));
}

class ReluGradTest : public MNNTestCase {
public:
    virtual ~ReluGradTest() = default;

protected:
    bool testOnBackend(MNNForwardType type, const std::string& deviceName) {
        const int h = 4, w = 4, size = h * w;
        const std::vector<float> originInputData = {6.2025,  -0.0156, 0.0765, 6.1872, 0.0455, 6.3100,  0.0162, -0.1304,
                                                    -0.0330, 0.0641,  6.2964, 0.0452, 0.2203, -0.0665, 0.1727, 0.1119};
        const std::vector<float> inputGradData   = {1., 2., 3., 4., 2., 3., 4., 1., 3., 4., 1., 2., 4., 1., 2., 3.};
        std::vector<float> reluExpectedGrad(size), relu6ExpectedGrad(size);
        for (int i = 0; i < size; ++i) {
            bool positive        = (originInputData[i] > 0);
            bool under6          = (originInputData[i] < 6);
            reluExpectedGrad[i]  = (positive ? inputGradData[i] : 0);
            relu6ExpectedGrad[i] = ((positive && under6) ? inputGradData[i] : 0);
        }

        auto input            = _Input({1, 1, h, w}, NCHW, halide_type_of<float>());
        auto inputGrad        = _Input({1, 1, h, w}, NCHW, halide_type_of<float>());
        auto inputConvert     = _Convert(input, NC4HW4);
        auto inputGradConvert = _Convert(inputGrad, NC4HW4);
        auto reluGrad         = _Convert(_ReluGrad(inputConvert, inputGradConvert), NCHW);
        auto relu6Grad        = _Convert(_Relu6Grad(inputConvert, inputGradConvert), NCHW);

        const std::vector<int> outDim = {1, 1, h, w};
        auto reluGradDim              = reluGrad->getInfo()->dim;
        auto relu6GradDim             = relu6Grad->getInfo()->dim;
        if (!checkVector<int>(reluGradDim.data(), outDim.data(), 4, 0)) {
            MNN_ERROR("ReluGrad(%s) shape test failed!\n", deviceName.c_str());
            return false;
        }
        if (!checkVector<int>(relu6GradDim.data(), outDim.data(), 4, 0)) {
            MNN_ERROR("Relu6Grad(%s) shape test failed!\n", deviceName.c_str());
            return false;
        }

        ::memcpy(input->writeMap<float>(), originInputData.data(), size * sizeof(float));
        ::memcpy(inputGrad->writeMap<float>(), inputGradData.data(), size * sizeof(float));
        if (!checkVector<float>(reluGrad->readMap<float>(), reluExpectedGrad.data(), size, 1e-6)) {
            MNN_ERROR("ReluGrad(%s) test failed!\n", deviceName.c_str());
            return false;
        }
        if (!checkVector<float>(relu6Grad->readMap<float>(), relu6ExpectedGrad.data(), size, 1e-6)) {
            MNN_ERROR("Relu6Grad(%s) test failed!\n", deviceName.c_str());
            return false;
        }
        return true;
    }
};

class ReluGradTestOnCPU : public ReluGradTest {
public:
    virtual ~ReluGradTestOnCPU() = default;
    virtual bool run() {
        return testOnBackend(MNN_FORWARD_CPU, "CPU");
    }
};

class ReluGradTestOnOpencl : public ReluGradTest {
public:
    virtual ~ReluGradTestOnOpencl() = default;
    virtual bool run() {
        return testOnBackend(MNN_FORWARD_OPENCL, "OPENCL");
    }
};

MNNTestSuiteRegister(ReluGradTestOnCPU, "op/ReluGrad");
